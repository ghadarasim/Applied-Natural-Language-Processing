{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVGC8vt4prsG"
   },
   "source": [
    "# Applied Natural Language Processing 955G5\n",
    "## Computer Based Examination, 2023\n",
    "\n",
    "Remember, you can add cells and change their type (between code and text/markdown) as required to answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVjTFWYKpvRS"
   },
   "outputs": [],
   "source": [
    "# update your candidate number here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTDVYEeyZxPS"
   },
   "source": [
    "#Question 2 (50 marks)\n",
    "\n",
    "This questions is about document classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tftq795GZuDb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ghadah Al-\n",
      "[nltk_data]     Chaab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### do not change the code in this cell\n",
    "# make sure you run this cell\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "positive_reviews=[\"great product\",\n",
    "                  \"excellent value\",\n",
    "                  \"performance was excellent\",\n",
    "                  \"very very good\",\n",
    "                  \"best of its kind\"]\n",
    "\n",
    "negative_reviews=[\"extremely poor\",\n",
    "                  \"would not recommend\",\n",
    "                  \"did not work\",\n",
    "                  \"very poor product\",\n",
    "                  \"not ideal\"]\n",
    "\n",
    "unlabelled_review=\"great value\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2QfbNcvV-cK"
   },
   "source": [
    "a) Why is stopword removal often applied in document classification tasks? What impact might it have on a classifier trained on the reviews above? (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr8zty9dWTIU"
   },
   "source": [
    "Stopword removal is often applied in document classification tasks to improve the performance and accuracy of the classifier. Stopwords are commonly used words in a language that do not carry significant meaning, such as \"the,\" \"is,\" and \"and.\" These words appear frequently in text but do not contribute much to the overall sentiment or meaning of the document.\n",
    "\n",
    "Stopwords are commonly used words in a language (such as \"the,\" \"and,\" \"is,\" \"in\") that don't carry significant meaning on their own. Removing them can help reduce noise in the text data and highlight the more important words.  In document classification, the focus is often on words that provide contextual information about the topic or sentiment. Removing stopwords allows the classifier to pay more attention to these contextually important words. In the provided reviews, words like \"great,\" \"excellent,\" \"very good,\" \"best,\" \"poor,\" \"not recommend,\" \"did not work,\" and \"poor product\" are indicative of sentiment. Removing stopwords could emphasize these sentiment-bearing words, making it easier for the classifier to detect the overall sentiment in the text. By removing stopwords, the classifier can focus on the more important and meaningful words in the reviews. This can help reduce noise and improve the classifier's ability to identify the sentiment or category of the document accurately.\n",
    "\n",
    "In the case of the reviews mentioned above, removing stopwords could potentially have a positive impact on the classifier's performance. It would allow the classifier to focus on the key words that truly convey the sentiment of the reviews, rather than being influenced by common, less informative words. This can lead to more accurate classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cfslnjtbb12B"
   },
   "source": [
    "b)\n",
    "\n",
    "i) Tokenize the reviews in the lists `positive_reviews` and `negative_reviews` to produce two new lists called `positive_tokenized` and `negative_tokenized`. For example, the list `[\"this is a review\", \"this is another\"]` would become `[[\"this\", \"is\", \"a\", \"review\"], [\"this\", \"is\", \"another\"]]`. (6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "t87u3PS2cNMh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Tokenized: [['great', 'product'], ['excellent', 'value'], ['performance', 'was', 'excellent'], ['very', 'very', 'good'], ['best', 'of', 'its', 'kind']]\n",
      "Negative Tokenized: [['extremely', 'poor'], ['would', 'not', 'recommend'], ['did', 'not', 'work'], ['very', 'poor', 'product'], ['not', 'ideal']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pos_tokenized = [word_tokenize(review) for review in positive_reviews]\n",
    "neg_tokenized = [word_tokenize(review) for review in negative_reviews]\n",
    "\n",
    "print(\"Positive Tokenized:\", pos_tokenized)\n",
    "print(\"Negative Tokenized:\", neg_tokenized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GroEkOZgcMYx"
   },
   "source": [
    "ii) Construct a training dataset from the lists of positive and negative tokenized reviews, consisting of a list of two element tuples in which the first element contains the list of tokens and the second element is either \"pos\" or \"neg\", indicating the sentiment of the review. For example, the positive review `[\"a\", \"good\", \"review\"]` would be represented in the training set as `([\"a\", \"good\", \"review\"], \"pos\")` (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YtqPrbVTeL0q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: [(['great', 'product'], 'pos'), (['excellent', 'value'], 'pos'), (['performance', 'was', 'excellent'], 'pos'), (['very', 'very', 'good'], 'pos'), (['best', 'of', 'its', 'kind'], 'pos'), (['extremely', 'poor'], 'neg'), (['would', 'not', 'recommend'], 'neg'), (['did', 'not', 'work'], 'neg'), (['very', 'poor', 'product'], 'neg'), (['not', 'ideal'], 'neg')]\n"
     ]
    }
   ],
   "source": [
    "# Create the training dataset\n",
    "training_dataset = [(tokens, \"pos\") for tokens in pos_tokenized] + [(tokens, \"neg\") for tokens in neg_tokenized]\n",
    "\n",
    "print(\"Training Dataset:\", training_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqyB8-sqejm6"
   },
   "source": [
    "iii) Convert the reviews to a bag-of-words representation using the FreqDist class. For example, the document `[\"this\", \"is\", \"a\", \"review\"]` would become `FreqDist({'this': 1, 'is': 1, 'a': 1, 'review': 1})`. The result should a be a list of pairs, in which one item is the bag-of-words review representation and the other is the sentiment label. (6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-9Kl_ItueoaU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag_of_Words Dataset: [(FreqDist({'great': 1, 'product': 1}), 'pos'), (FreqDist({'excellent': 1, 'value': 1}), 'pos'), (FreqDist({'performance': 1, 'was': 1, 'excellent': 1}), 'pos'), (FreqDist({'very': 2, 'good': 1}), 'pos'), (FreqDist({'best': 1, 'of': 1, 'its': 1, 'kind': 1}), 'pos'), (FreqDist({'extremely': 1, 'poor': 1}), 'neg'), (FreqDist({'would': 1, 'not': 1, 'recommend': 1}), 'neg'), (FreqDist({'did': 1, 'not': 1, 'work': 1}), 'neg'), (FreqDist({'very': 1, 'poor': 1, 'product': 1}), 'neg'), (FreqDist({'not': 1, 'ideal': 1}), 'neg')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Create bag-of-words representations\n",
    "pos_bag = [FreqDist(tokens) for tokens in pos_tokenized]\n",
    "neg_bag = [FreqDist(tokens) for tokens in neg_tokenized]\n",
    "\n",
    "# Create pairs with bag-of-words representations and sentiment labels\n",
    "pos_dataset = [(fdist, \"pos\") for fdist in pos_bag]\n",
    "neg_dataset = [(fdist, \"neg\") for fdist in neg_bag]\n",
    "\n",
    "# Combine positive and negative datasets\n",
    "bag_of_words_dataset = pos_dataset + neg_dataset\n",
    "\n",
    "print(\"Bag_of_Words Dataset:\", bag_of_words_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKKuhOEDfTP3"
   },
   "source": [
    "c)\n",
    "\n",
    "i) From the training data, calculate the prior probabilities, $p(c)$, of a review being in each sentiment class, $c \\in \\{ pos , neg \\}$. \n",
    "$$ p(c) = \\frac{freq(c)}{N}$$\n",
    "Here, $freq(c)$ is the number of documents with label $c$, and $N$ is the total number of documents. The result should be a dictionary whose keys are class labels and whose values are class probabilities. (6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YUkF5QwKgtEL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities: {'pos': 0.5, 'neg': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Calculate the total number of documents\n",
    "total_documents = len(bag_of_words)\n",
    "\n",
    "# Calculate the frequency of each sentiment class\n",
    "sentiment_frequencies = FreqDist(label for _, label in bag_of_words_dataset)\n",
    "\n",
    "# Calculate the prior probabilities\n",
    "prior_probabilities = {label: freq / total_documents for label, freq in sentiment_frequencies.items()}\n",
    "\n",
    "print(\"Prior Probabilities:\", prior_probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYr71EFKhyba"
   },
   "source": [
    "ii) Calculate the conditional probabilities, $p(f|c)$, of each token feature, $f$, given each sentiment class, $c$.\n",
    "$$ p(f|c) = \\frac{freq(f,c)}{freq(c)}$$ \n",
    "\n",
    "Where $freq(f,c)$ is the number of documents in class $c$ containing feature $f$ and $freq(c)$ is the total number of documents in class $c$. The result should be a dictionary of dictionaries, with the outer keys being token features, and the inner keys being class labels whose corresponding values are the conditional probabilities. (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9xyKOBNaicjp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Probabilities: defaultdict(<class 'dict'>, {'pos': {'great': 0.07142857142857142, 'product': 0.07142857142857142, 'excellent': 0.14285714285714285, 'value': 0.07142857142857142, 'performance': 0.07142857142857142, 'was': 0.07142857142857142, 'very': 0.14285714285714285, 'good': 0.07142857142857142, 'best': 0.07142857142857142, 'of': 0.07142857142857142, 'its': 0.07142857142857142, 'kind': 0.07142857142857142}, 'neg': {'extremely': 0.07692307692307693, 'poor': 0.15384615384615385, 'would': 0.07692307692307693, 'not': 0.23076923076923078, 'recommend': 0.07692307692307693, 'did': 0.07692307692307693, 'work': 0.07692307692307693, 'very': 0.07692307692307693, 'product': 0.07692307692307693, 'ideal': 0.07692307692307693}})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "# Create a defaultdict to store token frequencies for each class\n",
    "token_frequencies_by_class = defaultdict(lambda: FreqDist())\n",
    "\n",
    "# Count token frequencies for each class\n",
    "for token_fdist, label in bag_of_words:\n",
    "    token_frequencies_by_class[label] += token_fdist\n",
    "\n",
    "# Calculate conditional probabilities\n",
    "conditional_probabilities = defaultdict(dict)\n",
    "\n",
    "for token, fdist in token_frequencies_by_class.items():\n",
    "    total_tokens_in_class = sum(fdist.values())\n",
    "    for label, freq in fdist.items():\n",
    "        conditional_probabilities[token][label] = freq / total_tokens_in_class\n",
    "\n",
    "print(\"Conditional Probabilities:\", conditional_probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgU4yI5YqJka"
   },
   "source": [
    "iii) Use the priors and conditional probabilities to make a Naive Bayes prediction of the sentiment class for the unlabelled review. (6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q4CI0NYrrBA5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment Class: pos\n"
     ]
    }
   ],
   "source": [
    "unlabelled_review = \"great value\"  # Your unlabelled review here\n",
    "\n",
    "# Tokenize the unlabelled review\n",
    "tokenized_unlabelled_review = word_tokenize(unlabelled_review)\n",
    "\n",
    "# Initialize variables to store the maximum posterior probability and its associated class\n",
    "max_posterior_prob = -1\n",
    "predicted_class = None\n",
    "\n",
    "# Iterate through each sentiment class\n",
    "for sentiment_class, prior in prior_probabilities.items():\n",
    "    posterior_prob = prior\n",
    "    \n",
    "    # Calculate the product of conditional probabilities for each token\n",
    "    for token in tokenized_unlabelled_review:\n",
    "        if token in conditional_probabilities:\n",
    "            posterior_prob *= conditional_probabilities[token].get(sentiment_class, 1e-10)  # Use a small epsilon for tokens not in the training data\n",
    "        \n",
    "    # Update the predicted class if the posterior probability is greater\n",
    "    if posterior_prob > max_posterior_prob:\n",
    "        max_posterior_prob = posterior_prob\n",
    "        predicted_class = sentiment_class\n",
    "\n",
    "print(\"Predicted Sentiment Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fSLG0dF2Cz0"
   },
   "source": [
    "d)\n",
    "\n",
    "i) If you apply the Naive Bayes model to the training data using the class priors and conditional probabilities calculated so far, without smoothing, then you will find that you get predictions of 100% accuracy. What can we say about precision, recall and F1 in this case? (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDH-apUw2jyQ"
   },
   "source": [
    "if the Naive Bayes model is applied to the training data without smoothing and achieves 100% accuracy in predictions, we can make the following observations about precision, recall, and F1 score:\n",
    "\n",
    "Precision: Precision is the measure of how many of the predicted positive instances are actually positive. In this case, if the model achieves 100% accuracy, it means that all the positive instances are correctly identified. Therefore, the precision would also be 100%.\n",
    "\n",
    "Recall: Recall is the measure of how many of the actual positive instances are correctly identified. Since the model achieves 100% accuracy, it means that all the actual positive instances are correctly identified. Therefore, the recall would also be 100%.\n",
    "\n",
    "F1 score: The F1 score is the harmonic mean of precision and recall and provides a balanced measure of the model's performance. In this case, since both precision and recall are 100%, the F1 score would also be 100%.\n",
    "It is important to note that achieving 100% accuracy in predictions without smoothing is quite rare and may indicate overfitting to the training data. In real-world scenarios, it is common to have some level of error or misclassification, and the precision, recall, and F1 score would reflect that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wODZIWbS2pk_"
   },
   "source": [
    "ii) Should we apply smoothing in this case? Justify your answer. (6 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing can be applied to the estimated probability distributions in the context of Naive Bayes classification. The document mentions that the simplest form of smoothing is add-one smoothing, where a count of 1 is added to all the counts when estimating the probability of a feature given a class. This helps handle unseen features by assigning a small probability to them.\n",
    "\n",
    "Smoothing helps improve the model's generalization ability by accounting for unseen or rare features, preventing the model from assigning zero probabilities to them. By using add-one smoothing or similar techniques, the model becomes more robust and avoids overfitting to the training data.\n",
    "in conclusion, applying smoothing to a Naive Bayes model is recommended for several reasons:Overfitting Concerns, Handling Unseen Words, Variance Reduction, Generalization, Validation/Test Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJNS6sOUBlaF"
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
